---
title: "Sensor Grab Munge"
author: "Sam Struthers- CSU ROSSyndicate"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(dplyr.summarise.inform = FALSE)
source("src/setup_libraries.R")

fix_sites <- function(df) {
  fixed_df <- df %>%
    mutate(site = tolower(site)) %>%
    # renaming all the sites, just in case
    mutate(site = case_when(
      grepl("tamasag", site, ignore.case = TRUE) ~ str_replace(site, "tamasag", "bellvue"),
      grepl("legacy", site, ignore.case = TRUE) ~ str_replace(site, "legacy", "salyer"),
      grepl("lincoln", site, ignore.case = TRUE) ~ str_replace(site, "lincoln", "udall"),
       grepl("timberline", site, ignore.case = TRUE) ~ str_replace(site, "timberline", "riverbend"),
      grepl("prospect", site, ignore.case = TRUE) ~ str_replace(site, "prospect", "cottonwood"),
      grepl("timberline", site, ignore.case = TRUE) ~ str_replace(site, "timberline", "riverbend"),
      grepl("prospect", site, ignore.case = TRUE) ~ str_replace(site, "prospect", "cottonwood"),
      grepl("boxelder", site, ignore.case = TRUE) ~ str_replace(site, "boxelder", "elc"),
       grepl("archery", site, ignore.case = TRUE) ~ str_replace(site, "archery", "archery"),
      grepl("archery", site, ignore.case = TRUE) ~ str_replace(site, "archery", "archery"),
      grepl("river bluffs", site, ignore.case = TRUE) ~ str_replace(site, "river bluffs", "riverbluffs"),
      TRUE ~ site)
    )
  return(fixed_df)
}

```

# Read in sensor data

This comes from the 01_sensor_data_prep.rmd script and should be updated when an API pull, QAQC is updated or as more data is verified. 

```{r}

#list.files(path = "data/upper_clp_dss/sensor/prepped/", full.names = TRUE)

all_sensor_data_wide <- read_parquet(file = "data/upper_clp_dss/sensor/prepped/all_sensor_data_2023-09-01_2025-07-15.parquet")

```


# pull in grab sample data

## ROSS

```{r}

#discrete sample data and location metadata from most recent pub

source("src/pull_ROSS_zenodo_data.R")
zenodo_data <- pull_ROSS_zenodo_data(data_version = "v2025.07.01", DOI = "15883685", save_folder_dir = "data/upper_clp_dss/ross_clp_chem")

# Grab the water chemistry dataset

ross_water_chem <- zenodo_data[["most_recent_chem"]]%>%
  mutate(site_code = tolower(site_code), 
         #fixing site names based on sonde deployments with ROSS/Virridy sondes
         site_code = case_when(site_code == "archery" & DT_mst <= ymd("2024-11-30") ~ "archery_virridy",
                          site_code == "timberline" & DT_mst <= ymd("2024-11-30") ~ "riverbend_virridy",
                          site_code == "prospect" & DT_mst <= ymd("2024-11-30") ~ "cottonwood_virridy",
                          #updating to new names
                          site_code == "timberline" & DT_mst >= ymd("2024-11-30") ~ "riverbend",
                          site_code == "prospect" & DT_mst >= ymd("2024-11-30") ~ "cottonwood",
                          site_code == "lincoln" ~ "udall", 
                          site_code == "legacy" ~ "salyer",
                          site_code == "boxelder" ~ "elc",
                          site_code == "tamasag" ~ "bellvue",
                          T ~ site_code))%>%
  filter(DT_mst >= as_date("2023-09-01"))%>%
  dplyr::select(site_code, 
         Date, 
         DT_sample = DT_mst,
         TOC, TN, DOC, ChlA, NO3, NH4, PO4, SC,Cl, lab_turb = Turbidity, TSS,DT_mst_char)%>%
  mutate(collector = "ROSS")
```

## Fort Collins UCLP Data

This is given to us by the City of Fort Collins Watershed Team (Diana Schmidt and Jared Heath). 
2025 Dataset is not yet finalized but can likely still be used for our first models


```{r}

FC_chem_2022_2024 <- read_csv("data/upper_clp_dss/fc_clp_chem/UCLP_CWQMP_database_2022-24.csv", show_col_types = F)%>%
  mutate(Date = as.POSIXct(Date, format = "%m/%d/%y"), 
         NO3 = NO3_N/ 0.2259, 
         SC = TDS/ 0.65, #converting TDS to SC
         Cl = as.numeric(Cl), 
         lab_turb = as.numeric(Turbidity),
         TN = as.numeric(TN_calc),
         ChlA = NA_integer_,
         DOC = NA_integer_, 
         NH4 = NA_integer_, 
         TSS = NA_integer_,
         site_code = tolower(ShortDesc))%>%
  #filter to the period of our sensor deployment and sites where we have sensors
  filter(site_code %in% c("chd", 'pbd', "sfm") & Date >= as_date("2023-09-01"))%>%
  #grab columns of interest
  dplyr::select(site_code, Date,
         TOC, TN, DOC, ChlA, NO3, NH4, PO4 = oPhos, SC,Cl, lab_turb, TSS)%>%
  mutate(collector = "FC")

FC_field_data_2022_2024 <- readxl::read_xlsx(path = "data/upper_clp_dss/fc_clp_chem/UCLP_field_data_2022-24.xlsx")%>%
  mutate(
    Date = as.Date(`Date (MM/DD/YYYY)`),
    # Combine date and time into one datetime column from MT to MST for consistency 
    dt_mst = with_tz(ymd_hms(paste(
      format(`Date (MM/DD/YYYY)`, "%Y-%m-%d"), 
      format(`Time (HH:MM:SS)`, "%H:%M:%S")
    ), tz = "America/Denver"), tzone = "MST"),
    # Remove numbers from site name
    site_code = tolower(gsub("\\d+", "", `Site Name`)), 
    DT_mst_char = as.character(dt_mst)
  )%>%
  dplyr::select(site_code, Date, DT_sample = dt_mst, DT_mst_char)
  
# Combine the chemistry data with the field data
FC_chem_2022_2024 <- FC_chem_2022_2024 %>%
  left_join(FC_field_data_2022_2024, by = c("site_code", "Date")) 


# Repeat for 2025 data (TOC only!)

FC_chem_2025 <- readxl::read_xlsx("data/upper_clp_dss/fc_clp_chem/UCLP_CWQMP_TOC_202504-202506.xlsx")%>%
  filter(grepl(x = `Parameter Name`, pattern = "Total Organic Carbon", ignore.case = TRUE), 
          `Entered Unit` == "mg/L",
         grepl(x = `Location Name`, pattern = "CHD|PBD|SFM|PBR", ignore.case = TRUE))%>%
  dplyr::select(
    Date = `Sampled Date`, 
    site_name = `Location Name`,
    value = `Corrected Result`
  )%>%
  mutate(site_code = case_when(
    grepl("PBR", site_name, ignore.case = TRUE) ~ "pbr",
    grepl("CHD", site_name, ignore.case = TRUE) ~ "chd",
    grepl("PBD", site_name, ignore.case = TRUE) ~ "pbd",
    grepl("SFM", site_name, ignore.case = TRUE) ~ "sfm",
    TRUE ~ NA_character_),
         TOC = as.numeric(value))%>%
  mutate(collector = "FC")%>%
  dplyr::select(site_code, Date, TOC, collector)

FC_field_data_2025 <- readxl::read_xlsx(path = "data/upper_clp_dss/fc_clp_chem/UCLP_field_data_04-062025.xlsx")%>%
  mutate(
    Date = as.Date(`Date (MM/DD/YYYY)`),
    # Combine date and time into one datetime column from MT to MST for consistency 
    dt_mst = with_tz(ymd_hms(paste(
      format(`Date (MM/DD/YYYY)`, "%Y-%m-%d"), 
      format(`Time (HH:MM:SS)`, "%H:%M:%S")
    ), tz = "America/Denver"), tzone = "MST"),
    # Remove numbers from site name
    site_code = tolower(gsub("\\d+", "", `Site Name`)), 
    DT_mst_char = as.character(dt_mst)
  )%>%
  dplyr::select(site_code, Date, DT_sample = dt_mst, DT_mst_char)


FC_chem_2025 <- FC_chem_2025 %>%
  left_join(FC_field_data_2025, by = c("site_code", "Date"))%>%
  na.omit()


FC_chem <- bind_rows(FC_chem_2022_2024, FC_chem_2025)


#write_csv(FC_chem, "data/FC_clp_chem/FC_testing_data.csv")
```

## Combine data
```{r}

water_chem <- bind_rows(ross_water_chem, FC_chem)%>%
  filter(site_code %in% unique(all_sensor_data_wide$site))

# ggplot(water_chem%>%
#          filter(site_code %in% c("sfm", "chd", "pbr")), aes(x = Date, y = TOC, color = collector)) +
#   geom_point() +
#   geom_line()+
#   facet_wrap(~site_code, scales = "free_y") +
#   labs(title = "Water Chemistry Data from Ross and FC",
#        x = "Date",
#        y = "TOC (mg/L)") +
#   theme_minimal()

```

## plot available data vs water chem

```{r}
all_sensor_data_wide%>%
  #filter(year(DT_round) == 2025)%>%
  ggplot(aes(x = DT_round, y = data_avail))+
  geom_point()+
  #create a vertical line when a sample from water chem was collected
  geom_vline(data = water_chem%>%rename(site = site_code), aes(xintercept = DT_sample), color = "red")+
  facet_wrap(~site, scales = "free_y")

```



# Find match ups between grabs and sensors

This works using the wide dataset and finds the most recent (forward looking) 15 minute timestep where all sensor parameters (SC, FDOM, Temp,Chl-a, Turbidity and Depth ) are available. In the instance where there is no data after a sample is collected (ie a sensor is removed for the year), it will find the most recent (backward looking) timestep

```{r}
# Function to find the most recent sensor data for each water chem sample
get_most_recent_sensor_data <- function(water_chem, all_sensor_data_wide) {
  
  # Create an empty list to store results
  result_list <- list()
  
  # Loop through each row in water_chem
  for (i in 1:nrow(water_chem)) {
    # Get the current water chemistry row
    current_row <- water_chem[i, ]
    
    # Filter the sensor data for the current site
    site_data <- all_sensor_data_wide %>%
      filter(site == current_row$site_code) %>%
      filter(date(DT_round) == date(current_row$DT_sample)) %>%
      filter(DT_round >= current_row$DT_sample) # Ensure sensor data is later than water chem data
    
    # Find the most recent sensor data
    most_recent_sensor <- site_data %>%
      arrange(DT_round)%>%
      slice_head(n = 1)
    
    if (nrow(most_recent_sensor) == 0) {
     # If no matching sensor data found look backwards first
    site_data <- all_sensor_data_wide %>%
      filter(site == current_row$site_code) %>%
      filter(date(DT_round) == date(current_row$DT_sample)) %>%
      filter(DT_round < current_row$DT_sample) # Ensure sensor data is later than water chem data
    
    # Find the most recent sensor data
    most_recent_sensor <- site_data %>%
      arrange(DT_round) %>%
      slice_tail(n = 1)
    }
    
    
    #If still no matching data is found, add NA values for sensor columns
    if (nrow(most_recent_sensor) == 0) {
      most_recent_sensor <- tibble(
        site = current_row$site_code,
        DT_round = NA,
        `Chl-a Fluorescence` = NA,
        `Specific Conductivity` = NA,
        Temperature = NA,
        Turbidity = NA,
        `FDOM Fluorescence` = NA, 
        Depth = NA
      )
    }
    
    # Combine the current water chemistry row with the most recent sensor data
    result_list[[i]] <- cbind(current_row, most_recent_sensor)
  }
  
  
  # Combine the list of results into a single dataframe
  final_result <- bind_rows(result_list)
  
  return(final_result)
}

# Apply the function to get the most recent sensor data for each water chemistry sample
final_data <- get_most_recent_sensor_data(water_chem, all_sensor_data_wide)%>%
  dplyr::select(mw_id = site_code, 
         sensor_datetime = DT_round, 
         lab_datetime = DT_sample,
         FDOM = `FDOM Fluorescence`,
         hrs_since_last_cleaning = hours_since_last_visit,
         Temp = Temperature,
         Sensor_Cond = `Specific Conductivity`,
         Sensor_Turb = Turbidity,
         Depth, 
         Chl_a = `Chl-a Fluorescence`,
         TOC, DOC,  TN, NO3, SC, Turbidity  = lab_turb, Conductivity = SC, Cl, collector)


```

# Check Matches

- We are losing quite a few samples for periods that have not been verified yet. In particular, we are missing a lot of samples from CHD, SFM and Udall in 2024. It is likely worth looking into which flags we can generally ignore to give ourselves more data before everything is completely manually verified. 


```{r}
# Count of how many did not match (sensor_datetime is NA)
final_data %>%
  filter(!is.na(TOC)) %>%
  mutate(year = year(lab_datetime))%>%
  group_by(year, mw_id) %>%
  summarise(n_missing = sum(is.na(sensor_datetime)), .groups = "drop")%>%
  arrange(desc(n_missing))


```



# Bind with Virridy data

```{r}

virridy_data <- read_csv("data/upper_clp_dss/modeling/parsed_data_virridy.csv")%>%
  dplyr::select(-"...1" )%>%
  mutate(mw_id = as.character(mw_id))%>%
  mutate(collector = "Virridy")
  
set.seed(123)
ross_sites <- tibble(mw_id = unique(final_data$mw_id))%>%
  mutate(id = sample(1:1000, nrow(.), replace = TRUE))

ROSS_model_data <- final_data%>%
  #removing samples with no match up
  filter(!is.na(sensor_datetime))%>%
  left_join(ross_sites, by = c("mw_id"))%>%
  mutate(sensor_datetime = as.character(sensor_datetime), 
         lab_datetime = as.character(lab_datetime), 
         mw_id = as.character(id))%>%
  dplyr::select(-id)
  


all_modeled_data <- ROSS_model_data%>%
  bind_rows(virridy_data)

write_csv(ROSS_model_data, "data/upper_clp_dss/modeling/parsed_data_ROSS.csv")
write_csv(all_modeled_data, "data/upper_clp_dss/modeling/parsed_data_ROSS_virridy.csv")


```



## Scratch

```{r}

# nonver_wide <- non_ver_data%>%
#   pivot_wider(id_cols = c("site", "DT_round"), names_from = parameter, values_from = value)%>%
#   mutate(DT_join = as.character(DT_round))

#loop through each site and add in the field notes data
# 
# add_field_notes <- function(site_oi){
#   
#   if(site_oi =="archery virridy"){
#     field_notes <- field_notes%>%
#       mutate(site = "archery virridy")
#   }
#   
#   site_data <- nonver_wide%>%
#     filter(site == site_oi)%>%
#     left_join(field_notes%>%filter(site == site_oi)%>%dplyr::select(-site), by = c("DT_join"))%>%
#    fill(last_site_visit, .direction = "down")
#   return(site_data)
# }
# 
# #map over the unique site in non_ver data to add in the field notes
# non_ver_data_clean <- map_dfr(unique(non_ver_data$site), add_field_notes)%>%
#   mutate(hours_since_last_visit = as.numeric(difftime(DT_round, last_site_visit, units = "hours")))%>%
#   filter(!is.na(hours_since_last_visit)) %>%
#   mutate(across(where(is.list), ~ map_dbl(.x, ~ ifelse(is.null(.), NA, .))))%>%
#   pivot_longer(cols = c("Chl-a Fluorescence":"Turbidity"), names_to = "parameter", values_to = "value")%>%
#   filter(!is.na(value))%>%
#   left_join(non_ver_data %>%dplyr::select(-value, -sensor_malfunction), by = c("site","parameter", "DT_round"))%>%
#   filter(is.na(flag))%>% 
#     mutate(
#       year = year(DT_round),
#       week = week(DT_round),
#       y_w = paste(year, "-", week),
#       day = yday(DT_round),
#       y_d = paste(year, "-", day)
#       )%>%
#   mutate(date = as.Date(DT_round))

#rm(non_ver_data, nonver_wide, verified_sensor_data)


```

