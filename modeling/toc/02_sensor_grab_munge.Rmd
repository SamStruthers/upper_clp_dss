---
title: "Sensor Grab Munge"
author: "Sam Struthers- CSU ROSSyndicate"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(dplyr.summarise.inform = FALSE)
source("src/setup_libraries.R")

fix_sites <- function(df) {
  fixed_df <- df %>%
    mutate(site = tolower(site)) %>%
    # renaming all the sites, just in case
    mutate(site = case_when(
      grepl("tamasag", site, ignore.case = TRUE) ~ str_replace(site, "tamasag", "bellvue"),
      grepl("legacy", site, ignore.case = TRUE) ~ str_replace(site, "legacy", "salyer"),
      grepl("lincoln", site, ignore.case = TRUE) ~ str_replace(site, "lincoln", "udall"),
       grepl("timberline", site, ignore.case = TRUE) ~ str_replace(site, "timberline", "riverbend"),
      grepl("prospect", site, ignore.case = TRUE) ~ str_replace(site, "prospect", "cottonwood"),
      grepl("timberline", site, ignore.case = TRUE) ~ str_replace(site, "timberline", "riverbend"),
      grepl("prospect", site, ignore.case = TRUE) ~ str_replace(site, "prospect", "cottonwood"),
      grepl("boxelder", site, ignore.case = TRUE) ~ str_replace(site, "boxelder", "elc"),
       grepl("archery", site, ignore.case = TRUE) ~ str_replace(site, "archery", "archery"),
      grepl("archery", site, ignore.case = TRUE) ~ str_replace(site, "archery", "archery"),
      grepl("river bluffs", site, ignore.case = TRUE) ~ str_replace(site, "river bluffs", "riverbluffs"),
      TRUE ~ site)
    )
  return(fixed_df)
}

```

# Read in sensor data

This comes from the 01_sensor_data_prep.rmd script and should be updated when an API pull, QAQC is updated or as more data is verified. 

```{r}

#list.files(path = "data/upper_clp_dss/sensor/prepped/", full.names = TRUE)

all_sensor_data_wide <- read_parquet(file = "data/upper_clp_dss/sensor/prepped/all_sensor_data_2023-03-30_2025-08-27.parquet")

```


# pull in grab sample data

## ROSS

```{r}

#discrete sample data and location metadata from most recent pub

source("src/pull_ROSS_zenodo_data.R")
zenodo_data <- pull_ROSS_zenodo_data(data_version = "v2025.07.01", DOI = "15883685", save_folder_dir = "data/upper_clp_dss/ross_clp_chem")

# Grab the water chemistry dataset

ross_water_chem <- zenodo_data[["most_recent_chem"]]%>%
  mutate(site_code = tolower(site_code), 
         #fixing site names based on sonde deployments with ROSS/Virridy sondes
         site_code = case_when(site_code == "archery" & DT_mst <= ymd("2024-11-30") ~ "archery_virridy",
                          site_code == "timberline" & DT_mst <= ymd("2024-11-30") ~ "riverbend_virridy",
                          site_code == "prospect" & DT_mst <= ymd("2024-11-30") ~ "cottonwood_virridy",
                          #updating to new names
                          site_code == "timberline" & DT_mst >= ymd("2024-11-30") ~ "riverbend",
                          site_code == "prospect" & DT_mst >= ymd("2024-11-30") ~ "cottonwood",
                          site_code == "lincoln" ~ "udall", 
                          site_code == "legacy" ~ "salyer",
                          site_code == "boxelder" ~ "elc",
                          site_code == "tamasag" ~ "bellvue",
                          T ~ site_code))%>%
  filter(DT_mst >= as_date("2023-09-01"))%>%
  distinct()%>%
  dplyr::select(site_code, 
         Date, 
         DT_sample = DT_mst,
         TOC, TN, DOC, ChlA, NO3, NH4, PO4, SC,Cl, lab_turb = Turbidity, TSS,DT_mst_char)%>%
  mutate(collector = "ROSS")
```

## Fort Collins UCLP Data

This is given to us by the City of Fort Collins Watershed Team (Diana Schmidt and Jared Heath). 
2025 Dataset is not yet finalized but can likely still be used for our first models


```{r}

FC_chem_2022_2024 <- read_csv("data/upper_clp_dss/fc_clp_chem/UCLP_CWQMP_database_2022-24.csv", show_col_types = F)%>%
  mutate(Date = as.POSIXct(Date, format = "%m/%d/%y"), 
         NO3 = NO3_N/ 0.2259, 
         SC = TDS/ 0.65, #converting TDS to SC
         Cl = as.numeric(Cl), 
         lab_turb = as.numeric(Turbidity),
         TN = as.numeric(TN_calc),
         ChlA = NA_integer_,
         DOC = NA_integer_, 
         NH4 = NA_integer_, 
         TSS = NA_integer_,
         site_code = tolower(ShortDesc))%>%
  #filter to the period of our sensor deployment and sites where we have sensors
  filter(site_code %in% c("chd", 'pbd', "sfm") & Date >= as_date("2023-09-01"))%>%
  #grab columns of interest
  dplyr::select(site_code, Date,
         TOC, TN, DOC, ChlA, NO3, NH4, PO4 = oPhos, SC,Cl, lab_turb, TSS)%>%
  mutate(collector = "FC")

FC_field_data_2022_2024 <- readxl::read_xlsx(path = "data/upper_clp_dss/fc_clp_chem/UCLP_field_data_2022-24.xlsx")%>%
  mutate(
    Date = as.Date(`Date (MM/DD/YYYY)`),
    # Combine date and time into one datetime column from MT to MST for consistency 
    dt_mst = with_tz(ymd_hms(paste(
      format(`Date (MM/DD/YYYY)`, "%Y-%m-%d"), 
      format(`Time (HH:MM:SS)`, "%H:%M:%S")
    ), tz = "America/Denver"), tzone = "MST"),
    # Remove numbers from site name
    site_code = tolower(gsub("\\d+", "", `Site Name`)), 
    DT_mst_char = as.character(dt_mst)
  )%>%
  dplyr::select(site_code, Date, DT_sample = dt_mst, DT_mst_char)
  
# Combine the chemistry data with the field data
FC_chem_2022_2024 <- FC_chem_2022_2024 %>%
  left_join(FC_field_data_2022_2024, by = c("site_code", "Date")) 


# Repeat for 2025 data (TOC only!)

FC_chem_2025 <- readxl::read_xlsx("data/upper_clp_dss/fc_clp_chem/UCLP_CWQMP_TOC_202504-202506.xlsx")%>%
  filter(grepl(x = `Parameter Name`, pattern = "Total Organic Carbon", ignore.case = TRUE), 
          `Entered Unit` == "mg/L",
         grepl(x = `Location Name`, pattern = "CHD|PBD|SFM|PBR", ignore.case = TRUE))%>%
  dplyr::select(
    Date = `Sampled Date`, 
    site_name = `Location Name`,
    value = `Corrected Result`
  )%>%
  mutate(site_code = case_when(
    grepl("PBR", site_name, ignore.case = TRUE) ~ "pbr",
    grepl("CHD", site_name, ignore.case = TRUE) ~ "chd",
    grepl("PBD", site_name, ignore.case = TRUE) ~ "pbd",
    grepl("SFM", site_name, ignore.case = TRUE) ~ "sfm",
    TRUE ~ NA_character_),
         TOC = as.numeric(value))%>%
  mutate(collector = "FC")%>%
  dplyr::select(site_code, Date, TOC, collector)

FC_field_data_2025 <- readxl::read_xlsx(path = "data/upper_clp_dss/fc_clp_chem/UCLP_field_data_04-062025.xlsx")%>%
  mutate(
    Date = as.Date(`Date (MM/DD/YYYY)`),
    # Combine date and time into one datetime column from MT to MST for consistency 
    dt_mst = with_tz(ymd_hms(paste(
      format(`Date (MM/DD/YYYY)`, "%Y-%m-%d"), 
      format(`Time (HH:MM:SS)`, "%H:%M:%S")
    ), tz = "America/Denver"), tzone = "MST"),
    # Remove numbers from site name
    site_code = tolower(gsub("\\d+", "", `Site Name`)), 
    DT_mst_char = as.character(dt_mst)
  )%>%
  dplyr::select(site_code, Date, DT_sample = dt_mst, DT_mst_char)


FC_chem_2025 <- FC_chem_2025 %>%
  left_join(FC_field_data_2025, by = c("site_code", "Date"))%>%
  na.omit()


FC_chem <- bind_rows(FC_chem_2022_2024, FC_chem_2025)


#write_csv(FC_chem, "data/FC_clp_chem/FC_testing_data.csv")
```

## Combine data
```{r}

water_chem <- bind_rows(ross_water_chem, FC_chem)%>%
  filter(site_code %in% unique(all_sensor_data_wide$site))

#save for later use
write_parquet(water_chem, "data/upper_clp_dss/modeling/ROSS_FC_water_chemistry.parquet")


# ggplot(water_chem%>%
#          filter(site_code %in% c("sfm", "chd", "pbr")), aes(x = Date, y = TOC, color = collector)) +
#   geom_point() +
#   geom_line()+
#   facet_wrap(~site_code, scales = "free_y") +
#   labs(title = "Water Chemistry Data from Ross and FC",
#        x = "Date",
#        y = "TOC (mg/L)") +
#   theme_minimal()

```

## plot available data vs water chem

```{r}


map(unique(all_sensor_data_wide$site), function(site_sel){
  p <- all_sensor_data_wide %>%
    filter(site == site_sel)%>% 
    mutate(date = as.Date(DT_round)) %>%
    summarize(data_avail = any(data_avail), .by = "date") %>%
    ggplot(aes(x = date, y = data_avail)) +
    geom_point() +
    geom_vline(data = water_chem %>% 
                 rename(site = site_code) %>% 
                 filter(site == site_sel & !is.na(TOC)) %>% 
                 mutate(date = as.Date(DT_sample)), 
               aes(xintercept = date), color = "red") +
    labs(title = paste("Data Availability for Site:", site_sel))
  
  print(p)
})

```



# Find match ups between grabs and sensors

This works using the wide dataset and finds the most recent (forward looking) 15 minute timestep where all sensor parameters (SC, FDOM, Temp,Chl-a, Turbidity and Depth ) are available. In the instance where there is no data after a sample is collected (ie a sensor is removed for the year), it will find the most recent (backward looking) timestep

```{r}

final_data <- map(1:nrow(water_chem), function(i) {
  # Get the current water chemistry row
  current_row <- water_chem[i, ]
  
  if(i/10 == round(i/10)) {
    cat("Processing row", i, "of", nrow(water_chem), "\n")
  }
  
  
  #get data from the day of sampling
  site_data <- all_sensor_data_wide %>%
  filter(site == current_row$site_code & 
         date(DT_round) == date(current_row$DT_sample) & 
         DT_round >= current_row$DT_sample & 
         data_avail == TRUE)

  # Find the most recent (forward looking) sensor data
  most_recent_sensor <- site_data %>%
    filter(DT_round >= current_row$DT_sample)%>%
    arrange(DT_round) %>%
    slice_head(n = 1)
  
  # If no forward match found, look backwards
  if (nrow(most_recent_sensor) == 0) {
    # Find the most recent sensor data (closest before sampling)
    most_recent_sensor <- site_data %>%
    filter(DT_round <= current_row$DT_sample)%>%
      arrange(desc(DT_round)) %>%
      slice_head(n = 1)
  }
  
  # If still no matching data is found, add NA values
  if (nrow(most_recent_sensor) == 0) {
    most_recent_sensor <- tibble(
      site = current_row$site_code,
      DT_round = NA,
      hours_since_last_visit = NA,
      `Chl-a Fluorescence` = NA,
      `Specific Conductivity` = NA,
      Temperature = NA,
      Turbidity = NA,
      `FDOM Fluorescence` = NA, 
      Depth = NA,
      data_avail = NA
    )
  }
  
  # Combine the current water chemistry row with the sensor data
  bind_cols(current_row, most_recent_sensor)
}) %>% 
  bind_rows()%>%
  #fix column names to match virridy
  dplyr::select(mw_id = site_code, 
         sensor_datetime = DT_round, 
         lab_datetime = DT_sample,
         FDOM = `FDOM Fluorescence`,
         hrs_since_last_cleaning = hours_since_last_visit,
         Temp = Temperature,
         Sensor_Cond = `Specific Conductivity`,
         Sensor_Turb = Turbidity,
         Depth, 
         Chl_a = `Chl-a Fluorescence`,
         TOC, DOC,  TN, NO3, SC, Turbidity  = lab_turb, Conductivity = SC, Cl, collector)


```

# Check Matches

- We are losing quite a few samples for periods that have not been verified yet. In particular, we are missing a lot of samples from CHD, SFM and Udall in 2024. It is likely worth looking into which flags we can generally ignore to give ourselves more data before everything is completely manually verified. 


```{r}
# Count of how many did not match (sensor_datetime is NA)
TOC_samples <- final_data %>%
  filter(!is.na(TOC)) 


missing_samples <- TOC_samples%>%
  mutate(year = year(lab_datetime))%>%
  group_by(year, mw_id) %>%
  summarise(n_missing = sum(is.na(sensor_datetime)), .groups = "drop")%>%
  arrange(desc(n_missing))

cat("Number of samples with no match up:\n", sum(missing_samples$n_missing), " of ", nrow(TOC_samples), "\n")
head(missing_samples)


```


## Create example plot of sensor TS 
Add grab sample DT as dashed black line and sensor match up as solid red line

```{r}

example_site <- "pfal"
site_title <- "Poudre Falls"

start_dt <- ymd_hm("2024-06-01 00:00", tz = "MST")
end_dt <- ymd_hm("2024-07-18 00:00", tz = "MST")

example_data <- all_sensor_data_wide%>%
  filter(site == example_site)%>%
  filter(between(DT_round,start_dt, end_dt))%>%
  mutate(date = as.Date(DT_round))%>%
  select(-Depth)%>%
  pivot_longer(cols = c("Chl-a Fluorescence":"Turbidity"), names_to = "parameter", values_to = "value")

example_grab <- final_data%>%
  filter(mw_id == example_site)%>%
  filter(between(lab_datetime, start_dt, end_dt))%>%
  mutate(lab_date = as.Date(lab_datetime),
         sensor_date = as.Date(sensor_datetime))

example_ts_grab <- ggplot(example_data, aes(x = DT_round, y = value)) +
  geom_line(color = "#E70870") +
  geom_vline(data = example_grab, aes(xintercept = lab_datetime), linetype = "dashed", color = "#002EA3") +
  geom_vline(data = example_grab %>% filter(!is.na(sensor_datetime)), aes(xintercept = sensor_datetime), linetype = "solid", color = "#256BF5") +
  facet_wrap(~parameter, scales = "free_y", ncol = 1) +
  labs(title = paste("Example Sensor Time Series at Site:", site_title),
       x = "Date",
       y = "Sensor Value") +
  ROSS_theme

ggsave(plot = example_ts_grab, "data/upper_clp_dss/figures/example_sensor_timeseries_pfal.png",
       width = 12, height = 8)

```



# Bind with Virridy data

```{r}

virridy_data <- read_csv("data/upper_clp_dss/modeling/parsed_data_virridy.csv")%>%
  dplyr::select(-"...1" )%>%
  mutate(mw_id = as.character(mw_id))%>%
  mutate(collector = "Virridy")
  

ROSS_model_data <- final_data%>%
  #removing samples with no match up
  filter(!is.na(sensor_datetime))%>%
  mutate(sensor_datetime = as.character(sensor_datetime), 
         lab_datetime = as.character(lab_datetime))


all_modeled_data <- ROSS_model_data%>%
  bind_rows(virridy_data)

write_csv(ROSS_model_data, "data/upper_clp_dss/modeling/parsed_data_ROSS.csv")
write_csv(all_modeled_data, "data/upper_clp_dss/modeling/parsed_data_ROSS_virridy.csv")


```



## Scratch

```{r}

# nonver_wide <- non_ver_data%>%
#   pivot_wider(id_cols = c("site", "DT_round"), names_from = parameter, values_from = value)%>%
#   mutate(DT_join = as.character(DT_round))

#loop through each site and add in the field notes data
# 
# add_field_notes <- function(site_oi){
#   
#   if(site_oi =="archery virridy"){
#     field_notes <- field_notes%>%
#       mutate(site = "archery virridy")
#   }
#   
#   site_data <- nonver_wide%>%
#     filter(site == site_oi)%>%
#     left_join(field_notes%>%filter(site == site_oi)%>%dplyr::select(-site), by = c("DT_join"))%>%
#    fill(last_site_visit, .direction = "down")
#   return(site_data)
# }
# 
# #map over the unique site in non_ver data to add in the field notes
# non_ver_data_clean <- map_dfr(unique(non_ver_data$site), add_field_notes)%>%
#   mutate(hours_since_last_visit = as.numeric(difftime(DT_round, last_site_visit, units = "hours")))%>%
#   filter(!is.na(hours_since_last_visit)) %>%
#   mutate(across(where(is.list), ~ map_dbl(.x, ~ ifelse(is.null(.), NA, .))))%>%
#   pivot_longer(cols = c("Chl-a Fluorescence":"Turbidity"), names_to = "parameter", values_to = "value")%>%
#   filter(!is.na(value))%>%
#   left_join(non_ver_data %>%dplyr::select(-value, -sensor_malfunction), by = c("site","parameter", "DT_round"))%>%
#   filter(is.na(flag))%>% 
#     mutate(
#       year = year(DT_round),
#       week = week(DT_round),
#       y_w = paste(year, "-", week),
#       day = yday(DT_round),
#       y_d = paste(year, "-", day)
#       )%>%
#   mutate(date = as.Date(DT_round))

#rm(non_ver_data, nonver_wide, verified_sensor_data)


```

