---
title: "Testing TOC preds"
author: "Matthew Ross & Sam Struthers-ROSSyndicate"
date: "2025-08-01"
output: html_document
---

# Package load

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
source("src/setup_libraries.R")

library(purrr)
library(ggplot2)
library(dplyr)
library(gridExtra)
library(grid)
library(Ckmeans.1d.dp)
library(DiagrammeR)
library(Metrics)
library(caret)
library(glue)
set.seed(123)
```

# Create scaling based on all sensor data

```{r}
# Read in all data to create scaling parameters
all_sensor_data_wide <- read_parquet("data/upper_clp_dss/sensor/prepped/all_sensor_data_2023-03-30_2025-08-27.parquet")

# Use the complete sensor dataset for scaling parameters (assuming sensor has all necessary columns already)
complete_sensor_data <- all_sensor_data_wide %>%
  mutate(month = lubridate::month(DT_round))%>%
  select(FDOM = `FDOM Fluorescence`,
         hrs_since_last_cleaning = hours_since_last_visit,
         Temp = Temperature,
         Sensor_Cond = `Specific Conductivity`,
         Sensor_Turb = Turbidity,
         Chl_a = `Chl-a Fluorescence`, 
         month)%>%

  mutate(#capping sensor turb at 1000 for outliers
         Sensor_Turb = ifelse(Sensor_Turb > 1000, 1000,
                              ifelse(Sensor_Turb <= 0, 0.01, Sensor_Turb)), # if turb is zero, replace with 0.01 to avoid division by zero
         log_sensor_turb = log(Sensor_Turb), 
         Chl_a = ifelse(Chl_a == 0,0.0001, Chl_a),# if Chl_A is zero, replace with 0.001 to avoid division by zero
         log_chl_a = log(Chl_a),
           #compute optical bands
         f_c_turb = FDOM/(Chl_a + Sensor_Turb + FDOM))%>%
  #remove NAs
  filter(!is.na(hrs_since_last_cleaning) & !is.na(f_c_turb) & !is.na(Temp)& !is.na(Sensor_Cond))
  
# Save the original min/max values for each numeric column
scaling_params <- complete_sensor_data %>%
  select(where(is.numeric)) %>%
  summarise(across(everything(), list(min = min, max = max), .names = "{.col}_{.fn}"))

# Save these parameters
#saveRDS(scaling_params, "data/upper_clp_dss/modeling/scaling_parameters_20250820.rds")
# Load saved scaling parameters
#scaling_params <- readRDS("data/upper_clp_dss/modeling/scaling_parameters_20250820.rds")

# Function to apply the same scaling to new data
apply_training_scale <- function(new_data, scaling_params) {
  numeric_cols <- names(select(new_data, where(is.numeric)))
  
  scaled_data <- new_data
  
  for (col in numeric_cols) {
    min_val <- scaling_params[[paste0(col, "_min")]]
    max_val <- scaling_params[[paste0(col, "_max")]]
    
    # Apply same min-max scaling as training data
    scaled_data[[col]] <- (new_data[[col]] - min_val) / (max_val - min_val)
  }
  
  return(scaled_data)
}
```


# Read in Data

```{r}
# Read in all matches data
all_matches <- read_csv(file = 'data/upper_clp_dss/modeling/parsed_data_ROSS_virridy.csv', show_col_types = F) %>%
    mutate(id = as.character(mw_id)) %>%
   mutate(#capping sensor turb at 1000 for outliers
         Sensor_Turb = ifelse(Sensor_Turb > 1000, 1000,
                              ifelse(Sensor_Turb <= 0, 0.001, Sensor_Turb)),
         log_sensor_turb = log(Sensor_Turb), 
           #compute optical bands
         f_c_turb = FDOM/(Chl_a + Sensor_Turb + FDOM), 
         log_chl_a = log(Chl_a))%>%
  #remove NAs
  filter(!is.na(hrs_since_last_cleaning) & !is.na(f_c_turb) & !is.na(Temp)& !is.na(Sensor_Cond))%>%
  mutate(clean_sensor_datetime = parse_date_time(sensor_datetime, orders = c("%Y-%m-%d %H:%M:%S", "%m/%d/%y %H:%M","%Y-%m-%d" )))%>%
  mutate(sensor_datetime = force_tz(clean_sensor_datetime, tzone = 'MST'), 
         month = lubridate::month(sensor_datetime))%>%
  #remove other parameters other than sensor values (to be normalized)
    select(  -NO3, -TN, -DOC, -Kjeldahl, -Phosphorus,  -clean_sensor_datetime, -Turbidity, -Conductivity, -Depth, -Cl, -mw_id)

# Apply scaling to dataset
all_matches_norm <- all_matches %>%
  #remove TOC
  select(-TOC)%>%
  #normalize data based on full sensor set from 01_sensor_data_prep.rmd and the chunk above
  apply_training_scale(., scaling_params)%>%
  #add back in TOC (non normalized)
  mutate(TOC = all_matches$TOC)%>%
  na.omit()

```

# Set aside testing dataset & select features

```{r}
features <- c('FDOM', 'Sensor_Turb', "log_sensor_turb", 'Sensor_Cond', 'Chl_a','Temp','f_c_turb', "log_chl_a" )
target  = "TOC"

all_matches_trimmed <- all_matches_norm%>%
    filter(!(id == "cbri" & between(sensor_datetime, "2024-10-08", "2024-10-10")))%>% #exclude a cbri sample taken during release
  filter(!(id == "pman" & between(sensor_datetime, "2025-05-28", "2025-06-01")))%>% #exclude a pman sample with bad sensor data
filter( id %nin% c("springcreek", "boxcreek"))


testing <- all_matches_trimmed %>%
  filter((year(sensor_datetime) == 2025 & id %in% c("chd", "sfm", "pbr", "pman", "pbd")))


train_val <- all_matches_trimmed %>%
  anti_join(testing)%>%
  select(id, any_of(features),TOC, sensor_datetime, collector)

```

## Create table of testing site/years vs training site years

```{r}

# Create a summary table of site and years for training/validation and testing datasets
train_val_summary <- train_val %>%
  mutate(year = year(sensor_datetime)) %>%
  group_by(id, year) %>%
  summarise(n_samples = n(), .groups = "drop") %>%
  arrange(id, year)
testing_summary <- testing %>%
  mutate(year = year(sensor_datetime)) %>%
  group_by(id, year) %>%
  summarise(n_samples = n(), .groups = "drop") %>%
  arrange(id, year)

# Combine summaries into one table
summary_table <- bind_rows(
  train_val_summary %>% mutate(dataset = "Train/Val"),
  testing_summary %>% mutate(dataset = "Test")
) %>%
  pivot_wider(names_from = dataset, values_from = n_samples, values_fill = 0) %>%
  arrange(id, year)

# The table should have two groups of columns: Train/Val and Test, with the year in ()

```




# Train all 4 models on train val

## Define and visualize folds

```{r}
# Define validation sets for each fold
val_set_1 <- c( "sfm", "105075514","salyer","10507600",  "penn","archery", "cbri")

val_set_2 <- c("105075583", "archery_virridy", "pbd"  , "105075569", "elc","riverbend"  )

val_set_3 <- c("pfal","105075545","joei",  "lbea", "riverbluffs" , "105075538"  )

val_set_4 <- c("chd",  "105075624",   "udall", "105075552")



# Function to create plots for a given fold
plot_fold <- function(fold_num, train_val) {
  val_set_name <- paste0("val_set_", fold_num)
  val_set <- train_val %>% filter(id %in% get(val_set_name))
  train_set <- train_val %>% filter(id %nin% get(val_set_name))
  
  prop_val <- round(nrow(val_set)/nrow(train_val), 2) * 100
  train_med <- round(median(train_set$TOC, na.rm = TRUE), 2)
  val_med <- round(median(val_set$TOC, na.rm = TRUE), 2)
  
  # Histogram
  hist <- ggplot(train_set, aes(x = TOC)) +
    geom_histogram(bins = 30, fill = "grey") +
    geom_histogram(data = val_set, aes(x = TOC), bins = 30, fill = "#E70870", alpha = 0.5) +
    labs(
      title = paste0("Fold Set ", fold_num, ": ", nrow(val_set), " samples (", prop_val, "%) in validation set"),
      subtitle = paste0("Validation Sites: ", paste(unique(val_set$id), collapse = ", ")),
      x = "TOC (mg/L)"
    ) +
    theme_minimal()
  
  # Boxplot
  box <- ggplot(
    train_set %>% mutate(set = "Train") %>% 
      bind_rows(val_set %>% mutate(set = "Validation")) %>% 
      mutate(set = factor(set, levels = c("Train", "Validation"))),
    aes(x = set, y = TOC, fill = set)
  ) +
    geom_boxplot() +
    scale_fill_manual(values = c("Train" = "#256BF5", "Validation" = "#E70870")) +
    labs(
      title = paste0("Train Median TOC: ",train_med, "\nVal Median TOC: ", val_med),
      x = "",
      y = "TOC (mg/L)",
      fill = "TV Group",
    ) +
    theme_minimal()
  
  # Combine plots
  ggarrange(hist, box, nrow = 1)
}

# Create a list to store all fold plots
fold_plots <- list()
for (i in 1:4) {
  fold_plots[[i]] <- plot_fold(i, train_val)
}
ggarrange(plotlist = fold_plots, ncol = 1)



```


## Grid search and train models
Create 4 seperate folds and 4 models, with one fold used for validation on each model. 

```{r}
source("src/xgboost_site_stratified_tuning.R")

folds <- tibble(
  fold = 1:4,
  val_ids = list(val_set_1, val_set_2, val_set_3, val_set_4)
)

model <- xgboost_site_stratified_tuning(
     data = train_val %>% select(TOC, id, any_of(features)),
     tune_grid = expand.grid(
       nrounds = 10000,
       max_depth = c(2, 3, 4),
       eta = c(0.001, 0.01, 0.1),
       gamma = c(0.6, 0.8),
       lambda = c(1, 2),
       alpha = c(0, 1),
       colsample_bytree = c(0.5, 0.8),
       min_child_weight = c(2,3,5),
       subsample = c(0.5, 0.8)
     ),
     target_col = "TOC",
     site_col = "id",
     fold_ids =  folds
  )

```

## Look at feature importance for each fold

```{r}
importance_list <- lapply(seq_along(model), function(i) {
  fold_model <- model[[i]]$model
  importance_matrix <- xgb.importance(feature_names = features, model = fold_model)
  importance_df <- as.data.frame(importance_matrix)
  importance_df$Fold <- paste("Fold", i)
  return(importance_df)
})

```


## Save files (smaller)
```{r}

small_models <- lapply(model, function(x) {
  m <- x$model   # extract model (xgboost object)
  
  #remove large unnecessary elements 
  if ("trainingData" %in% names(m)) m$trainingData <- NULL
  if ("call" %in% names(m)) m$call <- NULL
  if ("terms" %in% names(m)) m$terms <- NULL
  
  return(m)
})
saveRDS(small_models, file = paste0("data/upper_clp_dss/modeling/model_splits/toc_xgboost_models_light_",Sys.Date(),".rds"))

```


# Read in Model
```{r}

most_recent_file <- list.files("data/upper_clp_dss/modeling/model_splits", pattern = "toc_xgboost_models_light_.*\\.rds", full.names = TRUE) %>%
  tail(1)
model <- readRDS(most_recent_file)
```


# Calculate performance and apply to testing set

```{r}
# Convert testing and train_val datasets to matrices for prediction
testing_trim<- testing%>%filter(collector != "FC")

test_matrix <- testing_trim[, features]%>%
  mutate(across(everything(), as.numeric)) %>%
  as.matrix()

train_matrix <- train_val[, features]%>%
  mutate(across(everything(), as.numeric)) %>%
  as.matrix()

# Add predictions from each fold model as new columns
for (i in seq_along(model)) {
  fold_model <- model[[i]]$model
  col_name <- glue("{target}_guess_fold{i}")
  testing_trim[[col_name]] <- predict(fold_model, test_matrix)
  train_val[[col_name]] <- predict(fold_model, train_matrix)
}

fold_cols <- glue("{target}_guess_fold{seq_along(model)}")
ensemble_col <- glue("{target}_guess_ensemble")
testing_trim[[ensemble_col]] <- rowMeans(testing_trim[, fold_cols])
train_val[[ensemble_col]] <- rowMeans(train_val[, fold_cols])

#Join
all_preds <- bind_rows(testing_trim%>%mutate(group = "Test"), 
                       train_val%>%mutate(group = "Train"))

#compute metrics
metrics_tbl <- map_dfr(c(seq_along(model), "mean"), function(f) {
  col_name <- if (f == "mean") glue(ensemble_col) else glue("{target}_guess_fold{f}")

  all_preds %>%
    group_by(group) %>%
    summarise(
      model = as.character(f),
      rmse = rmse(.data[[target]], .data[[col_name]]),
      mae  = mae(.data[[target]], .data[[col_name]]),
      bias = bias(.data[[target]], .data[[col_name]]),
      .groups = "drop"
    )%>%
    ungroup()
})%>%
    arrange(group)

metrics_tbl


```



# Visualize

```{r}
# Function to generate a plot for a given prediction column
plot_train_val <- function(pred_col, data, fold_name) {
  
  test_data <- data %>%filter(group == "Test")
  # Calculate RMSE for annotation
  test_rmse <- rmse(test_data[[target]], test_data[[pred_col]]) %>% round(3)
  test_mae <- mae(test_data[[target]], test_data[[pred_col]]) %>% round(3)

  
  min_val <- min(data[[target]], na.rm = TRUE)
  max_val <- max(data[[target]], na.rm = TRUE)
  plot_range <- max_val - min_val
  
  box_width <- plot_range * 0.5
  box_height <- plot_range * 0.2
  box_xmin <- min_val + plot_range * 0.02
  box_xmax <- box_xmin + box_width
  box_ymax <- max_val - plot_range * 0.02
  box_ymin <- box_ymax - box_height
  text_x <- (box_xmin + box_xmax) / 2
  text_y1 <- box_ymax - box_height * 0.15
  text_y2 <- box_ymax - box_height * 0.5
  text_y3 <- box_ymax - box_height * 0.85
  
 ggplot(data, aes(x = .data[[target]], y = .data[[pred_col]], color = group, shape = collector)) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", size = 1.2) +
  
  # Training points (all same shape)
  geom_point(
    data = filter(data, group == "Train"),
    #shape = 16,  # solid circle
    size = 4,
    alpha = 0.6) +  
   geom_point( # Testing points (shape by id)
    data = filter(data, group == "Test"),
    #shape = 17,
    #aes(shape = id),
    size = 4,
    alpha = 0.9
  ) +
    annotate("rect", xmin = box_xmin, xmax = box_xmax, ymin = box_ymin, ymax = box_ymax,
             fill = "white", color = "black", alpha = 1, linewidth = 0.5) +
    annotate("text", x = text_x, y = text_y1, label = paste0("Training samples: n = ", (nrow(data)- nrow(test_data))),
             color = "black", size = 3) +
    annotate("text", x = text_x, y = text_y2, label = paste0("Testing samples: n = ", nrow(test_data)),
             color = "black", size = 3) +
    annotate("text", x = text_x, y = text_y3, label = paste0("Testing RMSE: ", test_rmse, 
                                                             " mg/L, MAE:", test_mae, " mg/L"),
             color = "black", fontface = 2, size = 3.5) +
    scale_color_manual(values = c("Train" = "#002EA3", "Test" = "#E70870")) +
    #scale_shape_manual(values = c("ROSS" = 15, "FC" = 17, "Virridy" = 19)) +
    labs(
      x = "Measured TOC (mg/L)",
      y = "Predicted TOC (mg/L)",
      color = "Model Group",
      #shape = "Site",
      title = fold_name
    ) +
    theme_bw(base_size = 16) +
    xlim(min_val, max_val) +
    ylim(min_val, max_val) +
    theme(
      plot.title = element_text(hjust = 0.5, face = "bold"),
      legend.position = c(0.975, 0.05),
      legend.justification = c("right", "bottom"),
      legend.box.background = element_rect(color = "black", fill = "white"),
      legend.margin = margin(6, 6, 6, 6)
    )
}


# 1. Plot each fold
for (i in seq_along(fold_cols)) {
  p <- plot_train_val(fold_cols[i], all_preds, fold_name = paste0("Fold ", i))
  plot(p)
  ggsave(glue("data/upper_clp_dss/modeling/model_splits/figures/model_fold_{i}.png"),
       plot = p, width = 10, height = 6, dpi = 500)
}

# 2. Single plot with all four folds
fold_plots <- lapply(seq_along(fold_cols), function(i) {
  plot_train_val(fold_cols[i], all_preds, fold_name = paste0("Fold ", i))
})

ggarrange(plotlist = fold_plots, ncol = 2, nrow = 2, common.legend = TRUE, legend = "bottom")
ggsave("data/upper_clp_dss/modeling/model_splits/figures/model_all_folds.png",
       width = 14, height = 8, dpi = 500)


#TODO: ADD error bars based on ensemble means

# 2. Plot ensemble
p_ensemble <- plot_train_val(ensemble_col, all_preds, fold_name = "Ensemble")
plot(p_ensemble)
ggsave("data/upper_clp_dss/modeling/model_splits/figures/model_ensemble.png",
       plot = p_ensemble, width = 12, height = 10, dpi = 500)
```

# Create global model 

```{r}
best_params <- tibble()
for(i in 1:length(model)){
  best_params <- bind_rows(best_params,  model[[i]]$model$params%>%
    as_tibble()%>%
    select(-c(objective, eval_metric, validate_parameters))%>%
    mutate(fold = i))
}
print(best_params)

# Prepare DMatrix objects
dtrain <- xgb.DMatrix(data = as.matrix(train_val[, features]), label = train_val$TOC)
dtest  <- xgb.DMatrix(data = as.matrix(testing[, features]), label = testing$TOC)

watchlist <- list(train = dtrain, eval = dtest)

# Train XGBoost model with all training data and validate on testing sites
xgb_model <- xgb.train(
  params = list(
    objective = "reg:squarederror",
    max_depth = 2,
    eta = 0.01,
    gamma = 0.6,
    colsample_bytree = 0.8,
    min_child_weight = 2,
    subsample = 0.8
  ),
  data = dtrain,
  nrounds = 20000,
  watchlist = watchlist,     
  early_stopping_rounds = 1000,
  print_every_n = 100
)



```



